{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Is7Y5jF62NbS",
    "outputId": "2708ab57-b98a-44e1-f5fa-d869e1d6176d"
   },
   "outputs": [],
   "source": [
    "#!yes | pip uninstall torchvison\n",
    "#!pip install -qU torchvision\n",
    "#!pip install sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ip2pCKBk2Nbb"
   },
   "source": [
    "# MNIST Training using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBncu3h-2Nbf"
   },
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). This tutorial will show how to train and test an MNIST model on SageMaker using PyTorch.\n",
    "\n",
    "For more information about the PyTorch in SageMaker, please visit [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers) and [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) github repositories.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4ZTYgZJC2Nbj"
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIATGR2MRZAFA7WTQXF\"\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"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\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIAR3MFUGLUM4XEJ2KZ\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"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\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = \"cs243-egg\"\n",
    "prefix = \"cifar10\"\n",
    "\n",
    "# role = \"arn:aws:iam::220239531584:role/service-role/AmazonSageMaker-ExecutionRole-20221130T191674\"\n",
    "role = \"arn:aws:iam::127518651112:role/service-role/AmazonSageMaker-ExecutionRole-20221201T173507\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ya1dYW2Nbk"
   },
   "source": [
    "## Data\n",
    "### Getting the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6OjazRY2Nbl",
    "outputId": "86c1c964-0c12-4f7f-a5cd-3d58f33aa827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "train_set = datasets.CIFAR10(root='../data/cifar10/train', train=True, download=True, \n",
    "                    transform=train_transform)\n",
    "val_set = datasets.CIFAR10(root='../data/cifar10/val', train=False, download=True, \n",
    "                    transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpP6733-2Nbn"
   },
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpgqsJ7i2Nbp",
    "outputId": "fdc7731e-86d8-4eb5-9da9-b569597b342d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://cs243-egg/cifar10\n"
     ]
    }
   ],
   "source": [
    "# inputs = sagemaker_session.upload_data(path=\"../data/cifar10\", bucket=bucket, key_prefix=prefix)\n",
    "# print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh9xhj192Nbr"
   },
   "source": [
    "## Train\n",
    "### Training script\n",
    "The `mnist.py` script provides all the code we need for training and hosting a SageMaker model (`model_fn` function to load a model).\n",
    "The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to.\n",
    "  These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_NUM_GPUS`: The number of gpus available in the current container.\n",
    "* `SM_CURRENT_HOST`: The name of the current container on the container network.\n",
    "* `SM_HOSTS`: JSON encoded list containing all the hosts .\n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance.\n",
    "\n",
    "Because the SageMaker imports the training script, you should put your training code in a main guard (``if __name__=='__main__':``) if you are using the same script to host your model as we do in this example, so that SageMaker does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For example, the script run by this notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rX7TiWSe2Nbu"
   },
   "source": [
    "### Run training in SageMaker\n",
    "\n",
    "The `PyTorch` class allows us to run our training function as a training job on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, the training instance type, and hyperparameters. In this case we are going to run our training job on 2 ```ml.c4.xlarge``` instances. But this example can be ran on one or multiple, cpu or gpu instances ([full list of available instances](https://aws.amazon.com/sagemaker/pricing/instance-types/)). The hyperparameters parameter is a dict of values that will be passed to your training script -- you can see how to access these values in the `mnist.py` script above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Tafh7jiZ2Nbv"
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "n_pipelines = 2\n",
    "\n",
    "pt_estimator = PyTorch(\n",
    "    entry_point=\"train_sagemaker.py\",\n",
    "    source_dir=\"models\",\n",
    "    role=role,\n",
    "    instance_count=n_pipelines,\n",
    "    instance_type=\"ml.g4dn.12xlarge\",\n",
    "    framework_version='1.12.1',\n",
    "    py_version='py38',\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\", \"batch-size\": 1000, \"n-microbatches\": 8, \"learning-rate\": 0.003},\n",
    "    # image_uri=\"763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.12.1-gpu-py38-cu113-ubuntu20.04-sagemaker\",\n",
    "    # distribution={\n",
    "    #     \"pytorchddp\": {\n",
    "    #         \"enabled\": True\n",
    "    #     }\n",
    "    # },\n",
    "    base_job_name=\"pipe-squeeze-pretrained-test\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnWmjvEt2Nbv"
   },
   "source": [
    "After we've constructed our `PyTorch` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFtlmgPr2Nbw",
    "outputId": "93a22368-134a-46ff-9d6c-845e9b80286a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 19:34:52 Starting - Starting the training job...\n",
      "2022-12-07 19:35:19 Starting - Preparing the instances for trainingProfilerReport-1670441691: InProgress\n",
      ".........\n",
      "2022-12-07 19:36:48 Downloading - Downloading input data...\n",
      "2022-12-07 19:37:08 Training - Downloading the training image.......................\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2022-12-07 19:41:08,685 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2022-12-07 19:41:08,724 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2022-12-07 19:41:08,733 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2022-12-07 19:41:08,741 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2022-12-07 19:41:09,297 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2022-12-07 19:41:09,346 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2022-12-07 19:41:09,395 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2022-12-07 19:41:09,407 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.12xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"batch-size\": 1000,\n",
      "        \"epochs\": 1,\n",
      "        \"learning-rate\": 0.003,\n",
      "        \"n-microbatches\": 32\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-127518651112/pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.g4dn.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_sagemaker.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"backend\":\"gloo\",\"batch-size\":1000,\"epochs\":1,\"learning-rate\":0.003,\"n-microbatches\":32}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=train_sagemaker.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.g4dn.12xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.12xlarge\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}}\u001b[0m\n",
      "\u001b[35mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[35mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=train_sagemaker\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[35mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-east-1-127518651112/pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.g4dn.12xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"batch-size\":1000,\"epochs\":1,\"learning-rate\":0.003,\"n-microbatches\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-127518651112/pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093/source/sourcedir.tar.gz\",\"module_name\":\"train_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.g4dn.12xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_sagemaker.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--batch-size\",\"1000\",\"--epochs\",\"1\",\"--learning-rate\",\"0.003\",\"--n-microbatches\",\"32\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[35mSM_HP_BATCH-SIZE=1000\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[35mSM_HP_LEARNING-RATE=0.003\u001b[0m\n",
      "\u001b[35mSM_HP_N-MICROBATCHES=32\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20221118-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 train_sagemaker.py --backend gloo --batch-size 1000 --epochs 1 --learning-rate 0.003 --n-microbatches 32\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-12-07 19:41:08,948 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-12-07 19:41:08,986 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2022-12-07 19:41:08,995 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-12-07 19:41:09,003 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-12-07 19:41:09,631 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2022-12-07 19:41:09,680 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2022-12-07 19:41:09,728 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2022-12-07 19:41:09,740 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.12xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"batch-size\": 1000,\n",
      "        \"epochs\": 1,\n",
      "        \"learning-rate\": 0.003,\n",
      "        \"n-microbatches\": 32\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-127518651112/pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_sagemaker.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"batch-size\":1000,\"epochs\":1,\"learning-rate\":0.003,\"n-microbatches\":32}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_sagemaker.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.12xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.12xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_sagemaker\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-127518651112/pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.g4dn.12xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"batch-size\":1000,\"epochs\":1,\"learning-rate\":0.003,\"n-microbatches\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-127518651112/pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093/source/sourcedir.tar.gz\",\"module_name\":\"train_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.12xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_sagemaker.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--batch-size\",\"1000\",\"--epochs\",\"1\",\"--learning-rate\",\"0.003\",\"--n-microbatches\",\"32\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=1000\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.003\u001b[0m\n",
      "\u001b[34mSM_HP_N-MICROBATCHES=32\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20221118-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train_sagemaker.py --backend gloo --batch-size 1000 --epochs 1 --learning-rate 0.003 --n-microbatches 32\u001b[0m\n",
      "\u001b[35mDistributed training - True\u001b[0m\n",
      "\u001b[35mNumber of gpus available - 4\u001b[0m\n",
      "\u001b[35mDownloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\u001b[0m\n",
      "\u001b[35m0%|          | 0.00/548M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m5%|▌         | 28.2M/548M [00:00<00:01, 295MB/s]\u001b[0m\n",
      "\u001b[35m11%|█         | 60.3M/548M [00:00<00:01, 320MB/s]\u001b[0m\n",
      "\u001b[35m17%|█▋        | 90.8M/548M [00:00<00:01, 309MB/s]\u001b[0m\n",
      "\u001b[35m22%|██▏       | 120M/548M [00:00<00:01, 243MB/s]\u001b[0m\n",
      "\u001b[35m28%|██▊       | 151M/548M [00:00<00:01, 267MB/s]\u001b[0m\n",
      "\u001b[35m34%|███▎      | 184M/548M [00:00<00:01, 290MB/s]\u001b[0m\n",
      "\u001b[35m39%|███▉      | 215M/548M [00:00<00:01, 302MB/s]\u001b[0m\n",
      "\u001b[35m45%|████▌     | 248M/548M [00:00<00:01, 313MB/s]\u001b[0m\n",
      "\u001b[35m51%|█████     | 280M/548M [00:00<00:00, 320MB/s]\u001b[0m\n",
      "\u001b[35m57%|█████▋    | 311M/548M [00:01<00:00, 320MB/s]\u001b[0m\n",
      "\u001b[35m63%|██████▎   | 343M/548M [00:01<00:00, 325MB/s]\u001b[0m\n",
      "\u001b[35m68%|██████▊   | 374M/548M [00:01<00:00, 326MB/s]\u001b[0m\n",
      "\u001b[35m74%|███████▍  | 406M/548M [00:01<00:00, 329MB/s]\u001b[0m\n",
      "\u001b[35m80%|███████▉  | 438M/548M [00:01<00:00, 332MB/s]\u001b[0m\n",
      "\u001b[35m86%|████████▌ | 470M/548M [00:01<00:00, 331MB/s]\u001b[0m\n",
      "\u001b[35m92%|█████████▏| 502M/548M [00:01<00:00, 328MB/s]\u001b[0m\n",
      "\u001b[35m97%|█████████▋| 533M/548M [00:01<00:00, 324MB/s]\u001b[0m\n",
      "\u001b[35m100%|██████████| 548M/548M [00:01<00:00, 313MB/s]\u001b[0m\n",
      "\n",
      "2022-12-07 19:41:30 Training - Training image download completed. Training in progress.\u001b[34mDistributed training - True\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 4\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\u001b[0m\n",
      "\u001b[34m0%|          | 0.00/548M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 7.94M/548M [00:00<00:06, 82.7MB/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 15.8M/548M [00:00<00:07, 76.8MB/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 23.2M/548M [00:00<00:07, 76.8MB/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 30.7M/548M [00:00<00:07, 77.3MB/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 38.1M/548M [00:00<00:06, 76.7MB/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 46.4M/548M [00:00<00:06, 80.0MB/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 54.0M/548M [00:00<00:07, 71.3MB/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 61.8M/548M [00:00<00:06, 74.2MB/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 69.2M/548M [00:00<00:06, 75.1MB/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 76.7M/548M [00:01<00:06, 76.2MB/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 84.2M/548M [00:01<00:06, 76.8MB/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 91.6M/548M [00:01<00:06, 74.0MB/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 98.7M/548M [00:01<00:06, 74.0MB/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 106M/548M [00:01<00:06, 73.8MB/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 114M/548M [00:01<00:05, 77.6MB/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 122M/548M [00:01<00:05, 78.7MB/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 129M/548M [00:01<00:05, 77.9MB/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 137M/548M [00:01<00:06, 69.7MB/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 144M/548M [00:02<00:06, 67.9MB/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 150M/548M [00:02<00:06, 68.6MB/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 158M/548M [00:02<00:05, 70.8MB/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 165M/548M [00:02<00:06, 60.4MB/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 173M/548M [00:02<00:05, 66.4MB/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 181M/548M [00:02<00:05, 71.2MB/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 188M/548M [00:02<00:05, 71.4MB/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 195M/548M [00:02<00:05, 73.5MB/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 202M/548M [00:02<00:04, 74.0MB/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 210M/548M [00:03<00:04, 71.6MB/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 217M/548M [00:03<00:04, 73.4MB/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 226M/548M [00:03<00:04, 78.1MB/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 234M/548M [00:03<00:04, 76.9MB/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 242M/548M [00:03<00:04, 79.9MB/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 250M/548M [00:03<00:04, 76.6MB/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 257M/548M [00:03<00:04, 74.1MB/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 265M/548M [00:03<00:03, 75.1MB/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 272M/548M [00:03<00:03, 74.0MB/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 279M/548M [00:03<00:03, 75.2MB/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 287M/548M [00:04<00:03, 72.1MB/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 295M/548M [00:04<00:03, 74.4MB/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 302M/548M [00:04<00:03, 74.8MB/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 309M/548M [00:04<00:03, 73.6MB/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 316M/548M [00:04<00:03, 74.1MB/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 324M/548M [00:04<00:03, 76.1MB/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 331M/548M [00:04<00:03, 64.1MB/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 339M/548M [00:04<00:03, 68.0MB/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 346M/548M [00:04<00:03, 69.3MB/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 352M/548M [00:05<00:03, 63.3MB/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 359M/548M [00:05<00:03, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 366M/548M [00:05<00:02, 66.1MB/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 372M/548M [00:05<00:02, 65.6MB/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 380M/548M [00:05<00:02, 68.7MB/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 386M/548M [00:05<00:02, 64.5MB/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 393M/548M [00:05<00:02, 67.0MB/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 400M/548M [00:05<00:02, 65.7MB/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 406M/548M [00:05<00:02, 65.0MB/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 412M/548M [00:06<00:02, 60.0MB/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 419M/548M [00:06<00:02, 59.2MB/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 427M/548M [00:06<00:01, 65.1MB/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 433M/548M [00:06<00:02, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 439M/548M [00:06<00:01, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 446M/548M [00:06<00:01, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 454M/548M [00:06<00:01, 68.1MB/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 460M/548M [00:06<00:01, 65.4MB/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 467M/548M [00:06<00:01, 66.0MB/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 473M/548M [00:07<00:01, 65.3MB/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 480M/548M [00:07<00:01, 67.6MB/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 487M/548M [00:07<00:00, 70.0MB/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 494M/548M [00:07<00:00, 63.3MB/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 500M/548M [00:07<00:00, 63.0MB/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 507M/548M [00:07<00:00, 65.3MB/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 513M/548M [00:07<00:00, 64.5MB/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 520M/548M [00:07<00:00, 65.8MB/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 527M/548M [00:07<00:00, 69.6MB/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 535M/548M [00:07<00:00, 72.8MB/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 542M/548M [00:08<00:00, 72.9MB/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 548M/548M [00:08<00:00, 70.3MB/s]\u001b[0m\n",
      "\u001b[35mTotal parameters in model: 143,667,240\u001b[0m\n",
      "\u001b[35mTotal parameters in stage 0: 260,160\u001b[0m\n",
      "\u001b[35mTotal parameters in stage 1: 2,065,408\u001b[0m\n",
      "\u001b[35mTotal parameters in stage 2: 8,259,584\u001b[0m\n",
      "\u001b[35mTotal parameters in stage 3: 133,082,088\u001b[0m\n",
      "\u001b[34mTotal parameters in model: 143,667,240\u001b[0m\n",
      "\u001b[34mTotal parameters in stage 0: 260,160\u001b[0m\n",
      "\u001b[34mTotal parameters in stage 1: 2,065,408\u001b[0m\n",
      "\u001b[34mTotal parameters in stage 2: 8,259,584\u001b[0m\n",
      "\u001b[34mTotal parameters in stage 3: 133,082,088\u001b[0m\n",
      "\u001b[35mInitialized the distributed environment: 'gloo' backend on 2 nodes. Current host rank is 1. Number of gpus: 4 | cuda.device_count: 4\u001b[0m\n",
      "\u001b[35mCreate data loader rank 1\u001b[0m\n",
      "\u001b[35mWorld size: 2, setting effective batch size to 500. Should be batch size / num input gpus.\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'gloo' backend on 2 nodes. Current host rank is 0. Number of gpus: 4 | cuda.device_count: 4\u001b[0m\n",
      "\u001b[34mCreate data loader rank 0\u001b[0m\n",
      "\u001b[34mWorld size: 2, setting effective batch size to 500. Should be batch size / num input gpus.\u001b[0m\n",
      "\u001b[34m[2022-12-07 19:41:41.541 algo-1:91 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-12-07 19:41:41.718 algo-1:91 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-12-07 19:41:41.719 algo-1:91 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-12-07 19:41:41.719 algo-1:91 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-12-07 19:41:41.720 algo-1:91 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-12-07 19:41:41.720 algo-1:91 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35m[2022-12-07 19:41:41.547 algo-2:92 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-12-07 19:41:41.732 algo-2:92 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2022-12-07 19:41:41.733 algo-2:92 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2022-12-07 19:41:41.733 algo-2:92 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2022-12-07 19:41:41.734 algo-2:92 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2022-12-07 19:41:41.734 algo-2:92 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mProcesses 25000/50000 (50%) of train data\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Processes 25000/50000 (50%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 5000/10000 (50%) of test data\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Processes 5000/10000 (50%) of test data\u001b[0m\n",
      "\u001b[35mProcesses 25000/50000 (50%) of train data\u001b[0m\n",
      "\u001b[35mDEBUG:__main__:Processes 25000/50000 (50%) of train data\u001b[0m\n",
      "\u001b[35mProcesses 5000/10000 (50%) of test data\u001b[0m\n",
      "\u001b[35mDEBUG:__main__:Processes 5000/10000 (50%) of test data\u001b[0m\n",
      "\u001b[35mStart Training device 1\u001b[0m\n",
      "\u001b[35mINFO:__main__:Start Training device 1\u001b[0m\n",
      "\u001b[35m0%|          | 0/50 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mStart Training device 0\u001b[0m\n",
      "\u001b[34mINFO:__main__:Start Training device 0\u001b[0m\n",
      "\u001b[34m0%|          | 0/50 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[35m2%|▏         | 1/50 [00:17<14:27, 17.71s/it]\u001b[0m\n",
      "\u001b[35m[W logger.cpp:314] Warning: Cuda time stats are not collected for multi-device modules. (function operator())\u001b[0m\n",
      "\u001b[35mINFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m2%|▏         | 1/50 [00:17<14:27, 17.71s/it]\u001b[0m\n",
      "\u001b[34m[W logger.cpp:314] Warning: Cuda time stats are not collected for multi-device modules. (function operator())\u001b[0m\n",
      "\u001b[34mINFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/50 [00:19<06:43,  8.41s/it]\u001b[0m\n",
      "\u001b[35m4%|▍         | 2/50 [00:19<06:43,  8.41s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/50 [00:21<04:12,  5.37s/it]\u001b[0m\n",
      "\u001b[35m6%|▌         | 3/50 [00:21<04:12,  5.37s/it]\u001b[0m\n",
      "\u001b[35m8%|▊         | 4/50 [00:23<03:00,  3.93s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/50 [00:23<03:00,  3.93s/it]\u001b[0m\n",
      "\u001b[35m10%|█         | 5/50 [00:24<02:21,  3.14s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 5/50 [00:24<02:21,  3.14s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/50 [00:26<01:57,  2.66s/it]\u001b[0m\n",
      "\u001b[35m12%|█▏        | 6/50 [00:26<01:57,  2.66s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 7/50 [00:28<01:41,  2.36s/it]\u001b[0m\n",
      "\u001b[35m14%|█▍        | 7/50 [00:28<01:41,  2.36s/it]\u001b[0m\n",
      "\u001b[35m16%|█▌        | 8/50 [00:30<01:31,  2.17s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 8/50 [00:30<01:31,  2.17s/it]\u001b[0m\n",
      "\u001b[35m18%|█▊        | 9/50 [00:31<01:23,  2.04s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 9/50 [00:31<01:23,  2.04s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 10/50 [00:33<01:17,  1.94s/it]\u001b[0m\n",
      "\u001b[35m20%|██        | 10/50 [00:33<01:17,  1.94s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 11/50 [00:35<01:13,  1.88s/it]\u001b[0m\n",
      "\u001b[35m22%|██▏       | 11/50 [00:35<01:13,  1.88s/it]\u001b[0m\n",
      "\u001b[35m24%|██▍       | 12/50 [00:36<01:09,  1.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 12/50 [00:36<01:09,  1.83s/it]\u001b[0m\n",
      "\u001b[35m26%|██▌       | 13/50 [00:38<01:06,  1.80s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 13/50 [00:38<01:06,  1.80s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 14/50 [00:40<01:04,  1.78s/it]\u001b[0m\n",
      "\u001b[35m28%|██▊       | 14/50 [00:40<01:04,  1.78s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 15/50 [00:42<01:01,  1.77s/it]\u001b[0m\n",
      "\u001b[35m30%|███       | 15/50 [00:42<01:01,  1.77s/it]\u001b[0m\n",
      "\u001b[35m32%|███▏      | 16/50 [00:43<00:59,  1.76s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 16/50 [00:43<00:59,  1.76s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 17/50 [00:45<00:57,  1.75s/it]\u001b[0m\n",
      "\u001b[35m34%|███▍      | 17/50 [00:45<00:57,  1.75s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 18/50 [00:47<00:55,  1.74s/it]\u001b[0m\n",
      "\u001b[35m36%|███▌      | 18/50 [00:47<00:55,  1.74s/it]\u001b[0m\n",
      "\u001b[35m38%|███▊      | 19/50 [00:49<00:53,  1.74s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 19/50 [00:49<00:53,  1.74s/it]\u001b[0m\n",
      "\u001b[35m40%|████      | 20/50 [00:50<00:52,  1.74s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 20/50 [00:50<00:52,  1.74s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 21/50 [00:52<00:50,  1.74s/it]\u001b[0m\n",
      "\u001b[35m42%|████▏     | 21/50 [00:52<00:50,  1.74s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 22/50 [00:54<00:48,  1.74s/it]\u001b[0m\n",
      "\u001b[35m44%|████▍     | 22/50 [00:54<00:48,  1.74s/it]\u001b[0m\n",
      "\u001b[35m46%|████▌     | 23/50 [00:56<00:46,  1.74s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 23/50 [00:56<00:46,  1.74s/it]\u001b[0m\n",
      "\u001b[35m48%|████▊     | 24/50 [00:57<00:45,  1.74s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 24/50 [00:57<00:45,  1.74s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 25/50 [00:59<00:43,  1.74s/it]\u001b[0m\n",
      "\u001b[35m50%|█████     | 25/50 [00:59<00:43,  1.74s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 26/50 [01:01<00:41,  1.74s/it]\u001b[0m\n",
      "\u001b[35m52%|█████▏    | 26/50 [01:01<00:41,  1.74s/it]\u001b[0m\n",
      "\u001b[35m54%|█████▍    | 27/50 [01:03<00:39,  1.73s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 27/50 [01:03<00:39,  1.73s/it]\u001b[0m\n",
      "\u001b[35m56%|█████▌    | 28/50 [01:04<00:38,  1.73s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 28/50 [01:04<00:38,  1.73s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 29/50 [01:06<00:36,  1.73s/it]\u001b[0m\n",
      "\u001b[35m58%|█████▊    | 29/50 [01:06<00:36,  1.73s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 30/50 [01:08<00:34,  1.73s/it]\u001b[0m\n",
      "\u001b[35m60%|██████    | 30/50 [01:08<00:34,  1.73s/it]\u001b[0m\n",
      "\u001b[35m62%|██████▏   | 31/50 [01:09<00:32,  1.73s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 31/50 [01:09<00:32,  1.73s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 32/50 [01:11<00:31,  1.73s/it]\u001b[0m\n",
      "\u001b[35m64%|██████▍   | 32/50 [01:11<00:31,  1.73s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 33/50 [01:13<00:29,  1.74s/it]\u001b[0m\n",
      "\u001b[35m66%|██████▌   | 33/50 [01:13<00:29,  1.74s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 34/50 [01:15<00:27,  1.74s/it]\u001b[0m\n",
      "\u001b[35m68%|██████▊   | 34/50 [01:15<00:27,  1.74s/it]\u001b[0m\n",
      "\u001b[35m70%|███████   | 35/50 [01:16<00:26,  1.74s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 35/50 [01:16<00:26,  1.74s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 36/50 [01:18<00:24,  1.74s/it]\u001b[0m\n",
      "\u001b[35m72%|███████▏  | 36/50 [01:18<00:24,  1.74s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 37/50 [01:20<00:22,  1.74s/it]\u001b[0m\n",
      "\u001b[35m74%|███████▍  | 37/50 [01:20<00:22,  1.74s/it]\u001b[0m\n",
      "\u001b[35m76%|███████▌  | 38/50 [01:22<00:20,  1.74s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 38/50 [01:22<00:20,  1.74s/it]\u001b[0m\n",
      "\u001b[35m78%|███████▊  | 39/50 [01:23<00:19,  1.74s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 39/50 [01:23<00:19,  1.74s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 40/50 [01:25<00:17,  1.74s/it]\u001b[0m\n",
      "\u001b[35m80%|████████  | 40/50 [01:25<00:17,  1.74s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 41/50 [01:27<00:15,  1.74s/it]\u001b[0m\n",
      "\u001b[35m82%|████████▏ | 41/50 [01:27<00:15,  1.74s/it]\u001b[0m\n",
      "\u001b[35m84%|████████▍ | 42/50 [01:29<00:13,  1.74s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 42/50 [01:29<00:13,  1.74s/it]\u001b[0m\n",
      "\u001b[35m86%|████████▌ | 43/50 [01:30<00:12,  1.74s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 43/50 [01:30<00:12,  1.74s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 44/50 [01:32<00:10,  1.74s/it]\u001b[0m\n",
      "\u001b[35m88%|████████▊ | 44/50 [01:32<00:10,  1.74s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 45/50 [01:34<00:08,  1.74s/it]\u001b[0m\n",
      "\u001b[35m90%|█████████ | 45/50 [01:34<00:08,  1.74s/it]\u001b[0m\n",
      "\u001b[35m92%|█████████▏| 46/50 [01:35<00:06,  1.74s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 46/50 [01:35<00:06,  1.74s/it]\u001b[0m\n",
      "\u001b[35m94%|█████████▍| 47/50 [01:37<00:05,  1.74s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 47/50 [01:37<00:05,  1.74s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 48/50 [01:39<00:03,  1.74s/it]\u001b[0m\n",
      "\u001b[35m96%|█████████▌| 48/50 [01:39<00:03,  1.74s/it]\u001b[0m\n",
      "\u001b[35m98%|█████████▊| 49/50 [01:41<00:01,  1.74s/it]\u001b[0m\n",
      "\u001b[35m100%|██████████| 50/50 [01:42<00:00,  1.74s/it]\u001b[0m\n",
      "\u001b[35m100%|██████████| 50/50 [01:42<00:00,  2.06s/it]\u001b[0m\n",
      "\u001b[35mEpoch 1/1   Device 1   Train loss: 3.150   Validation loss: 1.809   Validation accuracy: 0.303\u001b[0m\n",
      "\u001b[35mINFO:__main__:Epoch 1/1   Device 1   Train loss: 3.150   Validation loss: 1.809   Validation accuracy: 0.303\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"train_sagemaker.py\", line 301, in <module>\u001b[0m\n",
      "\u001b[35mtrain(args)\n",
      "  File \"train_sagemaker.py\", line 256, in train\u001b[0m\n",
      "\u001b[35mtimer.save_summary(timer_summary_pth, train_params)\n",
      "  File \"/opt/ml/code/timer.py\", line 122, in save_summary\u001b[0m\n",
      "\u001b[35mwith open(json_file_path, \"w\") as fp:\u001b[0m\n",
      "\u001b[35mFileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/output_rank1/rank1_32_None_None_2022-12-07 19:43:28.903943.json'\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 49/50 [01:41<00:01,  1.74s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 50/50 [01:42<00:00,  1.74s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 50/50 [01:42<00:00,  2.06s/it]\u001b[0m\n",
      "\u001b[34mEpoch 1/1   Device 0   Train loss: 3.164   Validation loss: 1.799   Validation accuracy: 0.310\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 1/1   Device 0   Train loss: 3.164   Validation loss: 1.799   Validation accuracy: 0.310\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\u001b[0m\n",
      "\u001b[34mFile \"train_sagemaker.py\", line 301, in <module>\u001b[0m\n",
      "\u001b[34mtrain(args)\n",
      "  File \"train_sagemaker.py\", line 256, in train\u001b[0m\n",
      "\u001b[34mtimer.save_summary(timer_summary_pth, train_params)\n",
      "  File \"/opt/ml/code/timer.py\", line 122, in save_summary\u001b[0m\n",
      "\u001b[34mwith open(json_file_path, \"w\") as fp:\u001b[0m\n",
      "\u001b[34mFileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/output_rank0/rank0_32_None_None_2022-12-07 19:43:28.915426.json'\u001b[0m\n",
      "\u001b[35m2022-12-07 19:43:30,943 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2022-12-07 19:43:30,943 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[35m2022-12-07 19:43:30,944 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[35m2022-12-07 19:43:30,944 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[35mExitCode 1\u001b[0m\n",
      "\u001b[35mErrorMessage \"FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/output_rank1/rank1_32_None_None_2022-12-07 19:43:28.903943.json'\"\u001b[0m\n",
      "\u001b[35mCommand \"/opt/conda/bin/python3.8 train_sagemaker.py --backend gloo --batch-size 1000 --epochs 1 --learning-rate 0.003 --n-microbatches 32\"\u001b[0m\n",
      "\u001b[35m2022-12-07 19:43:30,944 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\u001b[34m2022-12-07 19:43:31,011 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-12-07 19:43:31,012 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-12-07 19:43:31,012 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2022-12-07 19:43:31,012 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/output_rank0/rank0_32_None_None_2022-12-07 19:43:28.915426.json'\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 train_sagemaker.py --backend gloo --batch-size 1000 --epochs 1 --learning-rate 0.003 --n-microbatches 32\"\u001b[0m\n",
      "\u001b[34m2022-12-07 19:43:31,012 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2022-12-07 19:43:53 Uploading - Uploading generated training model\n",
      "2022-12-07 19:43:53 Failed - Training job failed\n",
      "ProfilerReport-1670441691: Stopping\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/output_rank0/rank0_32_None_None_2022-12-07 19:43:28.915426.json'\"\nCommand \"/opt/conda/bin/python3.8 train_sagemaker.py --backend gloo --batch-size 1000 --epochs 1 --learning-rate 0.003 --n-microbatches 32\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/erg1/Desktop/SMDataScienceCourseContent/CS243-Computer-Networks/pipe-squeeze/src/launch_sagemaker.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/erg1/Desktop/SMDataScienceCourseContent/CS243-Computer-Networks/pipe-squeeze/src/launch_sagemaker.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pt_estimator\u001b[39m.\u001b[39;49mfit(\u001b[39m\"\u001b[39;49m\u001b[39ms3://cs243-egg/cifar10\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/torchtext_env/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:272\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[39mreturn\u001b[39;00m context\n\u001b[1;32m    270\u001b[0m     \u001b[39mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 272\u001b[0m \u001b[39mreturn\u001b[39;00m run_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/torchtext_env/lib/python3.8/site-packages/sagemaker/estimator.py:1128\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjobs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1127\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m-> 1128\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlatest_training_job\u001b[39m.\u001b[39;49mwait(logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniforge3/envs/torchtext_env/lib/python3.8/site-packages/sagemaker/estimator.py:2242\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[39m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2241\u001b[0m \u001b[39mif\u001b[39;00m logs \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_session\u001b[39m.\u001b[39;49mlogs_for_job(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjob_name, wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, log_type\u001b[39m=\u001b[39;49mlogs)\n\u001b[1;32m   2243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_session\u001b[39m.\u001b[39mwait_for_job(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/miniforge3/envs/torchtext_env/lib/python3.8/site-packages/sagemaker/session.py:4072\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   4069\u001b[0m             last_profiler_rule_statuses \u001b[39m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   4071\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m-> 4072\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_job_status(job_name, description, \u001b[39m\"\u001b[39;49m\u001b[39mTrainingJobStatus\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   4073\u001b[0m     \u001b[39mif\u001b[39;00m dot:\n\u001b[1;32m   4074\u001b[0m         \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/torchtext_env/lib/python3.8/site-packages/sagemaker/session.py:3603\u001b[0m, in \u001b[0;36mSession._check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3597\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCapacityError\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(reason):\n\u001b[1;32m   3598\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mCapacityError(\n\u001b[1;32m   3599\u001b[0m         message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   3600\u001b[0m         allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mCompleted\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mStopped\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   3601\u001b[0m         actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   3602\u001b[0m     )\n\u001b[0;32m-> 3603\u001b[0m \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   3604\u001b[0m     message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   3605\u001b[0m     allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mCompleted\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mStopped\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   3606\u001b[0m     actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   3607\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pipe-squeeze-pretrained-test-2022-12-07-19-34-47-093: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/output_rank0/rank0_32_None_None_2022-12-07 19:43:28.915426.json'\"\nCommand \"/opt/conda/bin/python3.8 train_sagemaker.py --backend gloo --batch-size 1000 --epochs 1 --learning-rate 0.003 --n-microbatches 32\", exit code: 1"
     ]
    }
   ],
   "source": [
    "pt_estimator.fit(\"s3://cs243-egg/cifar10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZZ7dA5g2Nbx"
   },
   "source": [
    "## Host\n",
    "### Create endpoint\n",
    "After training, we use the `PyTorch` estimator object to build and deploy a `PyTorchPredictor`. This creates a Sagemaker Endpoint -- a hosted prediction service that we can use to perform inference.\n",
    "\n",
    "As mentioned above we have implementation of `model_fn` in the `mnist.py` script that is required. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers).\n",
    "\n",
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances, but you need to make sure that you return or save your model as a cpu model similar to what we did in `mnist.py`. Here we will deploy the model to a single ```ml.m4.xlarge``` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0QkysiM2Nbx",
    "outputId": "e7683c22-805d-4cc4-ba87-492b246dc015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvdAH0Qc2Nby"
   },
   "source": [
    "### Evaluate\n",
    "\n",
    "You can use the test images to evalute the endpoint. The accuracy of the model depends on how many it is trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIRZsR_h2Nby",
    "outputId": "d59eb82e-f57b-4af4-91ca-7fefa2caf421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte\n",
      "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte\t   train-labels-idx1-ubyte\n",
      "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls data/MNIST/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wu64Tl6h2Nbz",
    "outputId": "0cd1e3e8-baff-4dd2-b6c6-4745c53e38a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "data_dir = \"data/MNIST/raw\"\n",
    "with gzip.open(os.path.join(data_dir, \"t10k-images-idx3-ubyte.gz\"), \"rb\") as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28).astype(np.float32)\n",
    "\n",
    "mask = random.sample(range(len(images)), 16)  # randomly select some of the test images\n",
    "mask = np.array(mask, dtype=np.int)\n",
    "data = images[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VY7AAqXD2Nbz",
    "outputId": "33107cfc-8254-4ba9-b470-49b3ddbce576"
   },
   "outputs": [],
   "source": [
    "response = predictor.predict(np.expand_dims(data, axis=1))\n",
    "print(\"Raw prediction result:\")\n",
    "print(response)\n",
    "print()\n",
    "\n",
    "labeled_predictions = list(zip(range(10), response[0]))\n",
    "print(\"Labeled predictions: \")\n",
    "print(labeled_predictions)\n",
    "print()\n",
    "\n",
    "labeled_predictions.sort(key=lambda label_and_prob: 1.0 - label_and_prob[1])\n",
    "print(\"Most likely answer: {}\".format(labeled_predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6E6djnPl2Nb0"
   },
   "source": [
    "### Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMAiczyC2Nb0"
   },
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(endpoint_name=predictor.endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torchtext_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "vscode": {
   "interpreter": {
    "hash": "23f8c5db1711cd8e1b53cf86a360c6e6888c4b0339673576cbef61b2c9b6977e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
