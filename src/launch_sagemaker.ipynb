{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Is7Y5jF62NbS",
    "outputId": "2708ab57-b98a-44e1-f5fa-d869e1d6176d"
   },
   "outputs": [],
   "source": [
    "#!yes | pip uninstall torchvison\n",
    "!pip install -qU torchvision\n",
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ip2pCKBk2Nbb"
   },
   "source": [
    "# Pipe-Squeeze Experiments on CIFAR-10 with SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBncu3h-2Nbf"
   },
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "Setup for running Pipe-Squeeze experiments on CIFAR-10. Required that you setup SageMaker prior to running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZTYgZJC2Nbj"
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"<YOUR_ACCESS_KEY_ID>\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"<YOUR_SECRET_ACCESS_KEY>\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = \"<YOUR_S3_BUCKET>\"\n",
    "prefix = \"cifar10\"\n",
    "\n",
    "role = \"<YOUR_AWS_SAGEMAKER_ROLE>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ya1dYW2Nbk"
   },
   "source": [
    "## Data - CIFAR-10\n",
    "### Getting the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6OjazRY2Nbl",
    "outputId": "86c1c964-0c12-4f7f-a5cd-3d58f33aa827"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "train_set = datasets.CIFAR10(root='../data/cifar10/train', train=True, download=True, \n",
    "                    transform=train_transform)\n",
    "val_set = datasets.CIFAR10(root='../data/cifar10/val', train=False, download=True, \n",
    "                    transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpP6733-2Nbn"
   },
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpgqsJ7i2Nbp",
    "outputId": "fdc7731e-86d8-4eb5-9da9-b569597b342d"
   },
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"../data/cifar10\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh9xhj192Nbr"
   },
   "source": [
    "## Train\n",
    "### Training script\n",
    "The `train_sagemaker.py` script provides all the code we need for training and hosting a SageMaker model (`model_fn` function to load a model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rX7TiWSe2Nbu"
   },
   "source": [
    "### Run training in SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tafh7jiZ2Nbv"
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "n_pipelines = 3\n",
    "epochs = 10\n",
    "batch_size = 1000\n",
    "microbatches = 8\n",
    "learning_rate = 0.003\n",
    "compression_type = 'randomk'\n",
    "compression_ratio = 0.8\n",
    "pt_estimator = PyTorch(\n",
    "    entry_point=\"train_sagemaker.py\",\n",
    "    source_dir=\"models\",\n",
    "    role=role,\n",
    "    instance_count=n_pipelines,\n",
    "    instance_type=\"ml.g4dn.12xlarge\",\n",
    "    framework_version='1.12.1',\n",
    "    py_version='py38',\n",
    "    hyperparameters={\n",
    "        \"epochs\": epochs,\n",
    "        \"backend\": \"nccl\",\n",
    "        \"batch-size\": batch_size,\n",
    "        \"n-microbatches\": microbatches,\n",
    "        \"learning-rate\": learning_rate,\n",
    "        \"compression-type\": compression_type,\n",
    "        \"compression-ratio\": compression_ratio,\n",
    "    },\n",
    "    base_job_name=f\"three-pipes-{compression_type}\",\n",
    ")\n",
    "\n",
    "pt_estimator.fit(f\"s3://{bucket}/{prefix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment_dict = {'compression_type': ['randomk', 'randomk', 'randomk', 'powersgd'],\n",
    "                    'compression_ratio': [0.3, 0.5, 0.8, 1],\n",
    "                    }\n",
    "n_pipelines = 3\n",
    "\n",
    "for i in range(4):\n",
    "    pt_estimator = PyTorch(\n",
    "        entry_point=\"train_sagemaker.py\",\n",
    "        source_dir=\"models\",\n",
    "        role=role,\n",
    "        instance_count=n_pipelines,\n",
    "        instance_type=\"ml.g4dn.12xlarge\",\n",
    "        framework_version='1.12.1',\n",
    "        py_version='py38',\n",
    "        hyperparameters={\n",
    "            \"epochs\": epochs,\n",
    "            \"backend\": \"nccl\",\n",
    "            \"batch-size\": batch_size,\n",
    "            \"n-microbatches\": microbatches,\n",
    "            \"learning-rate\": learning_rate,\n",
    "            \"compression-type\": experiment_dict['compression_type'][i],\n",
    "            \"compression-ratio\": experiment_dict['compression_ratio'][i],\n",
    "        },\n",
    "        base_job_name=f\"three-pipes-{compression_type}\",\n",
    "    )\n",
    "    pt_estimator.fit(f\"s3://{bucket}/{prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnWmjvEt2Nbv"
   },
   "source": [
    "After we've constructed our `PyTorch` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "vscode": {
   "interpreter": {
    "hash": "23f8c5db1711cd8e1b53cf86a360c6e6888c4b0339673576cbef61b2c9b6977e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
